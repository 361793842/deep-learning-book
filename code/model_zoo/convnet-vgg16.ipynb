{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.6.0\n",
      "IPython 6.0.0\n",
      "\n",
      "tensorflow 1.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo -- Convolutional Neural Network (VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG-16 Convolutional Neural Network Architecture [1] implemented in TensorFlow and trained on Cifar-10 [2, 3] images.\n",
    "\n",
    "References:\n",
    "\n",
    "- [1] Simonyan, K., & Zisserman, A. (2015). [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556). International Conference on Learning Representations (ICRL), 1â€“14. https://doi.org/10.1016/j.infsof.2008.09.005\n",
    "- [2] Krizhevsky, A. (2009). [Learning Multiple Layers of Features from Tiny Images](https://doi.org/10.1.1.222.9220 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.222.9220&rep=rep1&type=pdf). Science Department, University of Toronto.\n",
    "- [3] https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cifar-10-python.tar.gz (162.6 Mb)\n",
      "Extracting cifar-10-python.tar.gz ...\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "from helper import download_and_extract_cifar\n",
    "from helper import Cifar10Loader\n",
    "\n",
    "dest = download_and_extract_cifar('./cifar-10')\n",
    "cifar = Cifar10Loader(dest)\n",
    "cifar.num_train\n",
    "\n",
    "X, y = cifar.load_test()\n",
    "half = cifar.num_test // 2\n",
    "X_test, X_valid = X[:half], X[half:]\n",
    "y_test, y_valid = y[:half], y[half:]\n",
    "\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpu:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0200 | Cost: 4249.833\n",
      "Minibatch: 0400 | Cost: 2246.514\n",
      "Minibatch: 0600 | Cost: 1692.409\n",
      "Minibatch: 0800 | Cost: 1254.097\n",
      "Minibatch: 1000 | Cost: 896.876\n",
      "Minibatch: 1200 | Cost: 875.512\n",
      "Minibatch: 1400 | Cost: 637.828\n",
      "Epoch: 001 | AvgCost: 5559.711 | Valid ACC: 0.284\n",
      "Minibatch: 0200 | Cost: 373.037\n",
      "Minibatch: 0400 | Cost: 269.688\n",
      "Minibatch: 0600 | Cost: 266.762\n",
      "Minibatch: 0800 | Cost: 296.835\n",
      "Minibatch: 1000 | Cost: 256.392\n",
      "Minibatch: 1200 | Cost: 185.515\n",
      "Minibatch: 1400 | Cost: 128.045\n",
      "Epoch: 002 | AvgCost: 259.956 | Valid ACC: 0.281\n",
      "Minibatch: 0200 | Cost: 121.229\n",
      "Minibatch: 0400 | Cost: 95.311\n",
      "Minibatch: 0600 | Cost: 61.695\n",
      "Minibatch: 0800 | Cost: 75.399\n",
      "Minibatch: 1000 | Cost: 71.741\n",
      "Minibatch: 1200 | Cost: 45.392\n",
      "Minibatch: 1400 | Cost: 45.823\n",
      "Epoch: 003 | AvgCost: 87.557 | Valid ACC: 0.265\n",
      "Minibatch: 0200 | Cost: 40.045\n",
      "Minibatch: 0400 | Cost: 42.742\n",
      "Minibatch: 0600 | Cost: 37.271\n",
      "Minibatch: 0800 | Cost: 31.965\n",
      "Minibatch: 1000 | Cost: 29.277\n",
      "Minibatch: 1200 | Cost: 30.988\n",
      "Minibatch: 1400 | Cost: 20.649\n",
      "Epoch: 004 | AvgCost: 35.575 | Valid ACC: 0.252\n",
      "Minibatch: 0200 | Cost: 16.200\n",
      "Minibatch: 0400 | Cost: 18.978\n",
      "Minibatch: 0600 | Cost: 18.995\n",
      "Minibatch: 0800 | Cost: 18.815\n",
      "Minibatch: 1000 | Cost: 10.033\n",
      "Minibatch: 1200 | Cost: 5.191\n",
      "Minibatch: 1400 | Cost: 7.911\n",
      "Epoch: 005 | AvgCost: 15.228 | Valid ACC: 0.247\n",
      "Minibatch: 0200 | Cost: 10.551\n",
      "Minibatch: 0400 | Cost: 6.904\n",
      "Minibatch: 0600 | Cost: 5.280\n",
      "Minibatch: 0800 | Cost: 7.927\n",
      "Minibatch: 1000 | Cost: 6.404\n",
      "Minibatch: 1200 | Cost: 4.156\n",
      "Minibatch: 1400 | Cost: 4.521\n",
      "Epoch: 006 | AvgCost: 6.439 | Valid ACC: 0.246\n",
      "Minibatch: 0200 | Cost: 3.846\n",
      "Minibatch: 0400 | Cost: 3.727\n",
      "Minibatch: 0600 | Cost: 2.802\n",
      "Minibatch: 0800 | Cost: 2.957\n",
      "Minibatch: 1000 | Cost: 2.374\n",
      "Minibatch: 1200 | Cost: 2.881\n",
      "Minibatch: 1400 | Cost: 2.790\n",
      "Epoch: 007 | AvgCost: 3.271 | Valid ACC: 0.265\n",
      "Minibatch: 0200 | Cost: 2.304\n",
      "Minibatch: 0400 | Cost: 2.247\n",
      "Minibatch: 0600 | Cost: 1.872\n",
      "Minibatch: 0800 | Cost: 2.503\n",
      "Minibatch: 1000 | Cost: 2.178\n",
      "Minibatch: 1200 | Cost: 2.129\n",
      "Minibatch: 1400 | Cost: 2.003\n",
      "Epoch: 008 | AvgCost: 2.288 | Valid ACC: 0.276\n",
      "Minibatch: 0200 | Cost: 1.826\n",
      "Minibatch: 0400 | Cost: 1.971\n",
      "Minibatch: 0600 | Cost: 1.797\n",
      "Minibatch: 0800 | Cost: 1.854\n",
      "Minibatch: 1000 | Cost: 1.711\n",
      "Minibatch: 1200 | Cost: 1.893\n",
      "Minibatch: 1400 | Cost: 1.725\n",
      "Epoch: 009 | AvgCost: 1.940 | Valid ACC: 0.363\n",
      "Minibatch: 0200 | Cost: 1.692\n",
      "Minibatch: 0400 | Cost: 1.747\n",
      "Minibatch: 0600 | Cost: 2.085\n",
      "Minibatch: 0800 | Cost: 1.849\n",
      "Minibatch: 1000 | Cost: 2.049\n",
      "Minibatch: 1200 | Cost: 1.688\n",
      "Minibatch: 1400 | Cost: 1.706\n",
      "Epoch: 010 | AvgCost: 1.792 | Valid ACC: 0.369\n",
      "Minibatch: 0200 | Cost: 1.391\n",
      "Minibatch: 0400 | Cost: 2.060\n",
      "Minibatch: 0600 | Cost: 1.566\n",
      "Minibatch: 0800 | Cost: 1.651\n",
      "Minibatch: 1000 | Cost: 1.398\n",
      "Minibatch: 1200 | Cost: 1.427\n",
      "Minibatch: 1400 | Cost: 1.650\n",
      "Epoch: 011 | AvgCost: 1.646 | Valid ACC: 0.423\n",
      "Minibatch: 0200 | Cost: 1.812\n",
      "Minibatch: 0400 | Cost: 1.741\n",
      "Minibatch: 0600 | Cost: 1.635\n",
      "Minibatch: 0800 | Cost: 1.377\n",
      "Minibatch: 1000 | Cost: 1.834\n",
      "Minibatch: 1200 | Cost: 1.616\n",
      "Minibatch: 1400 | Cost: 1.660\n",
      "Epoch: 012 | AvgCost: 1.549 | Valid ACC: 0.417\n",
      "Minibatch: 0200 | Cost: 1.285\n",
      "Minibatch: 0400 | Cost: 1.537\n",
      "Minibatch: 0600 | Cost: 1.979\n",
      "Minibatch: 0800 | Cost: 1.507\n",
      "Minibatch: 1000 | Cost: 1.114\n",
      "Minibatch: 1200 | Cost: 1.326\n",
      "Minibatch: 1400 | Cost: 1.739\n",
      "Epoch: 013 | AvgCost: 1.465 | Valid ACC: 0.464\n",
      "Minibatch: 0200 | Cost: 1.663\n",
      "Minibatch: 0400 | Cost: 1.557\n",
      "Minibatch: 0600 | Cost: 1.559\n",
      "Minibatch: 0800 | Cost: 1.050\n",
      "Minibatch: 1000 | Cost: 1.155\n",
      "Minibatch: 1200 | Cost: 1.430\n",
      "Minibatch: 1400 | Cost: 1.206\n",
      "Epoch: 014 | AvgCost: 1.387 | Valid ACC: 0.510\n",
      "Minibatch: 0200 | Cost: 1.762\n",
      "Minibatch: 0400 | Cost: 1.424\n",
      "Minibatch: 0600 | Cost: 1.525\n",
      "Minibatch: 0800 | Cost: 1.155\n",
      "Minibatch: 1000 | Cost: 1.310\n",
      "Minibatch: 1200 | Cost: 1.561\n",
      "Minibatch: 1400 | Cost: 1.405\n",
      "Epoch: 015 | AvgCost: 1.316 | Valid ACC: 0.524\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 15\n",
    "batch_size = 32\n",
    "\n",
    "# Other\n",
    "print_interval = 200\n",
    "\n",
    "# Architecture\n",
    "image_width, image_height, image_depth = 32, 32, 3\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "### WRAPPER FUNCTIONS\n",
    "##########################\n",
    "\n",
    "def conv_layer(input, input_channels, output_channels, \n",
    "               kernel_size, strides, scope, padding='SAME'):\n",
    "    with tf.name_scope(scope):\n",
    "        weights_shape = kernel_size + [input_channels, output_channels]\n",
    "        weights = tf.Variable(tf.truncated_normal(shape=weights_shape,\n",
    "                                                  mean=0.0,\n",
    "                                                  stddev=0.1,\n",
    "                                                  dtype=tf.float32),\n",
    "                                                  name='weights')\n",
    "        biases = tf.Variable(tf.zeros(shape=[output_channels]),\n",
    "                             name='biases')\n",
    "        conv = tf.nn.conv2d(input=input,\n",
    "                            filter=weights,\n",
    "                            strides=strides,\n",
    "                            padding=padding,\n",
    "                            name='convolution')\n",
    "        out = tf.nn.bias_add(conv, biases, name='logits')\n",
    "        out = tf.nn.relu(out, name='activation')\n",
    "        return out\n",
    "\n",
    "\n",
    "def fc_layer(input, output_nodes, scope,\n",
    "             activation=None, seed=None):\n",
    "    with tf.name_scope(scope):\n",
    "        shape = int(np.prod(input.get_shape()[1:]))\n",
    "        flat_input = tf.reshape(input, [-1, shape])\n",
    "        weights = tf.Variable(tf.truncated_normal(shape=[shape,\n",
    "                                                         output_nodes],\n",
    "                                                  mean=0.0,\n",
    "                                                  stddev=0.1,\n",
    "                                                  dtype=tf.float32,\n",
    "                                                  seed=seed),\n",
    "                                                  name='weights')\n",
    "        biases = tf.Variable(tf.zeros(shape=[output_nodes]),\n",
    "                             name='biases')\n",
    "        act = tf.nn.bias_add(tf.matmul(flat_input, weights), biases, \n",
    "                             name='logits')\n",
    "\n",
    "        if activation is not None:\n",
    "            act = activation(act, name='activation')\n",
    "\n",
    "        return act\n",
    "\n",
    "\n",
    "##########################\n",
    "### GRAPH DEFINITION\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.placeholder(tf.float32, [None, image_width, image_height, image_depth], name='features')\n",
    "    tf_y = tf.placeholder(tf.float32, [None, n_classes], name='targets')\n",
    "     \n",
    "    ##########################\n",
    "    ### VGG16 Model\n",
    "    ##########################\n",
    "\n",
    "    # =========\n",
    "    # BLOCK 1\n",
    "    # =========\n",
    "    conv_layer_1 = conv_layer(input=tf_x,\n",
    "                              input_channels=3,\n",
    "                              output_channels=64,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv1')\n",
    "    \n",
    "    conv_layer_2 = conv_layer(input=conv_layer_1,\n",
    "                              input_channels=64,\n",
    "                              output_channels=64,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv2')    \n",
    "    \n",
    "    pool_layer_1 = tf.nn.max_pool(conv_layer_2,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool1') \n",
    "    # =========\n",
    "    # BLOCK 2\n",
    "    # =========\n",
    "    conv_layer_3 = conv_layer(input=pool_layer_1,\n",
    "                              input_channels=64,\n",
    "                              output_channels=128,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv3')    \n",
    "    \n",
    "    conv_layer_4 = conv_layer(input=conv_layer_3,\n",
    "                              input_channels=128,\n",
    "                              output_channels=128,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv4')    \n",
    "    \n",
    "    pool_layer_2 = tf.nn.max_pool(conv_layer_4,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool2') \n",
    "    # =========\n",
    "    # BLOCK 3\n",
    "    # =========\n",
    "    conv_layer_5 = conv_layer(input=pool_layer_2,\n",
    "                              input_channels=128,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv5')        \n",
    "    \n",
    "    conv_layer_6 = conv_layer(input=conv_layer_5,\n",
    "                              input_channels=256,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv6')      \n",
    "    \n",
    "    conv_layer_7 = conv_layer(input=conv_layer_6,\n",
    "                              input_channels=256,\n",
    "                              output_channels=256,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv7')\n",
    "    \n",
    "    pool_layer_3 = tf.nn.max_pool(conv_layer_7,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool3') \n",
    "    # =========\n",
    "    # BLOCK 4\n",
    "    # =========\n",
    "    conv_layer_8 = conv_layer(input=pool_layer_3,\n",
    "                              input_channels=256,\n",
    "                              output_channels=512,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv8')      \n",
    "    \n",
    "    conv_layer_9 = conv_layer(input=conv_layer_8,\n",
    "                              input_channels=512,\n",
    "                              output_channels=512,\n",
    "                              kernel_size=[3, 3],\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              scope='conv9')     \n",
    "    \n",
    "    conv_layer_10 = conv_layer(input=conv_layer_9,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv10')   \n",
    "    \n",
    "    pool_layer_4 = tf.nn.max_pool(conv_layer_10,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool4') \n",
    "    # =========\n",
    "    # BLOCK 5\n",
    "    # =========\n",
    "    conv_layer_11 = conv_layer(input=pool_layer_4,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv11')   \n",
    "    \n",
    "    conv_layer_12 = conv_layer(input=conv_layer_11,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv12')   \n",
    "\n",
    "    conv_layer_13 = conv_layer(input=conv_layer_12,\n",
    "                               input_channels=512,\n",
    "                               output_channels=512,\n",
    "                               kernel_size=[3, 3],\n",
    "                               strides=[1, 1, 1, 1],\n",
    "                               scope='conv13') \n",
    "    \n",
    "    pool_layer_5 = tf.nn.max_pool(conv_layer_12,\n",
    "                                  ksize=[1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding='SAME',\n",
    "                                  name='pool5')     \n",
    "    # ===========\n",
    "    # CLASSIFIER\n",
    "    # ===========\n",
    "    \n",
    "    fc_layer_1 = fc_layer(input=pool_layer_5, \n",
    "                          output_nodes=4096,\n",
    "                          activation=tf.nn.relu,\n",
    "                          scope='fc1')\n",
    "    \n",
    "    fc_layer_2 = fc_layer(input=fc_layer_1, \n",
    "                          output_nodes=4096,\n",
    "                          activation=tf.nn.relu,\n",
    "                          scope='fc2')\n",
    "\n",
    "    out_layer = fc_layer(input=fc_layer_2, \n",
    "                         output_nodes=n_classes,\n",
    "                         activation=None,\n",
    "                         scope='output_layer')\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=tf_y)\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Prediction\n",
    "    correct_prediction = tf.equal(tf.argmax(tf_y, 1), tf.argmax(out_layer, 1), \n",
    "                                  name='correct_predictions')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "    # Saver to save session for reuse\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    \n",
    "##########################\n",
    "### TRAINING & EVALUATION\n",
    "##########################\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0.\n",
    "        mbatch_cnt = 0\n",
    "        for batch_x, batch_y in cifar.load_train_epoch(shuffle=True, batch_size=batch_size):\n",
    "            \n",
    "            mbatch_cnt += 1\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict={'features:0': batch_x,\n",
    "                                                            'targets:0': batch_y})\n",
    "            avg_cost += c\n",
    "\n",
    "            if not mbatch_cnt % print_interval:\n",
    "                print(\"Minibatch: %04d | Cost: %.3f\" % (mbatch_cnt, c))\n",
    "                \n",
    "\n",
    "        #valid_acc = sess.run('accuracy:0', feed_dict={'features:0': X_valid,\n",
    "        #                                              'targets:0': y_valid})\n",
    "        # ---------------------------------------\n",
    "        # workaround for GPUs with <= 4 Gb memory\n",
    "        n_predictions, n_correct = 0, 0\n",
    "        indices = np.arange(y_valid.shape[0])\n",
    "        chunksize = 500\n",
    "        for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
    "            index_slice = indices[start_idx:start_idx + chunksize]\n",
    "            p = sess.run('correct_predictions:0', \n",
    "                         feed_dict={'features:0': X_valid[index_slice],\n",
    "                                    'targets:0': y_valid[index_slice]})\n",
    "            n_correct += np.sum(p)\n",
    "            n_predictions += p.shape[0]\n",
    "        valid_acc = n_correct / n_predictions\n",
    "        # ---------------------------------------\n",
    "                                                \n",
    "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / mbatch_cnt), end=\"\")\n",
    "        print(\" | Valid ACC: %.3f\" % (valid_acc))\n",
    "    \n",
    "    saver.save(sess, save_path='./convnet-vgg16.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.539\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### RELOAD & TEST\n",
    "##########################\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    saver.restore(sess, save_path='./convnet-vgg16.ckpt')\n",
    "    \n",
    "    # test_acc = sess.run('accuracy:0', feed_dict={'features:0': X_test,\n",
    "    #                                              'targets:0': y_test})\n",
    "    # ---------------------------------------\n",
    "    # workaround for GPUs with <= 4 Gb memory\n",
    "    n_predictions, n_correct = 0, 0\n",
    "    indices = np.arange(y_test.shape[0])\n",
    "    chunksize = 500\n",
    "    for start_idx in range(0, indices.shape[0] - chunksize + 1, chunksize):\n",
    "        index_slice = indices[start_idx:start_idx + chunksize]\n",
    "        p = sess.run('correct_predictions:0', \n",
    "                     feed_dict={'features:0': X_test[index_slice],\n",
    "                                'targets:0': y_test[index_slice]})\n",
    "        n_correct += np.sum(p)\n",
    "        n_predictions += p.shape[0]\n",
    "    test_acc = n_correct / n_predictions\n",
    "    # ---------------------------------------\n",
    "\n",
    "    print('Test ACC: %.3f' % test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
